{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model='llama-3.1-70b-versatile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\varsh\\\\Documents\\\\AI\\\\LLM\\\\RAG_youtube_langchain\\\\code'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books directory: C:\\Users\\varsh\\Documents\\AI\\LLM\\RAG_youtube_langchain\\books\n",
      "Persistent directory: C:\\Users\\varsh\\Documents\\AI\\LLM\\RAG_youtube_langchain\\db\\chroma_db_with_metadata\n"
     ]
    }
   ],
   "source": [
    "books_dir = r'C:\\Users\\varsh\\Documents\\AI\\LLM\\RAG_youtube_langchain\\books'\n",
    "db_dir = os.path.join(r'C:\\Users\\varsh\\Documents\\AI\\LLM\\RAG_youtube_langchain', \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\")\n",
    "\n",
    "print(f\"Books directory: {books_dir}\")\n",
    "print(f\"Persistent directory: {persistent_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\varsh\\\\Documents\\\\AI\\\\LLM\\\\RAG_youtube_langchain\\\\books'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store already exists. No need to initialize.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(persistent_directory):\n",
    "    print(\"Persistent directory does not exist. Initializing vector store...\")\n",
    "\n",
    "    # Ensure the books directory exists\n",
    "    if not os.path.exists(books_dir):\n",
    "        raise FileNotFoundError(\n",
    "            f\"The directory {books_dir} does not exist. Please check the path.\"\n",
    "        )\n",
    "    book_files = [f for f in os.listdir(books_dir) if f.endswith(\".txt\")]\n",
    "    # print(book_files)\n",
    "    \n",
    "    \n",
    "    documents=[]\n",
    "    for bookfile in book_files:\n",
    "        file_path=os.path.join(books_dir,bookfile)\n",
    "        loader = TextLoader(file_path, encoding='utf-8')\n",
    "        book_docs=loader.load()\n",
    "        # print(book_docs)\n",
    "        for doc in book_docs:\n",
    "            # print(doc)\n",
    "            # break\n",
    "            doc.metadata = {\"source\": bookfile}\n",
    "            documents.append(doc)\n",
    "            print(documents)\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(\"\\n--- Document Chunks Information ---\")\n",
    "    print(f\"Number of document chunks: {len(docs)}\")\n",
    "    print(\"\\n--- Creating embeddings ---\")\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "    print(\"\\n--- Finished creating embeddings ---\")\n",
    "\n",
    "    # Create the vector store and persist it\n",
    "    print(\"\\n--- Creating and persisting vector store ---\")\n",
    "    db = Chroma.from_documents(\n",
    "        docs, embeddings, persist_directory=persistent_directory)\n",
    "    print(\"\\n--- Finished creating and persisting vector store ---\")\n",
    "\n",
    "else:\n",
    "    print(\"Vector store already exists. No need to initialize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_28228\\3350772227.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
      "c:\\Users\\varsh\\Documents\\AI\\LLM\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_28228\\3350772227.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=persistent_directory,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents ---\n",
      "Document 1:\n",
      "I had called upon my friend, Mr. Sherlock Holmes, one day in the\n",
      " autumn of last year and found him in deep conversation with a very\n",
      " stout, florid-faced, elderly gentleman with fiery red hair. With an\n",
      " apology for my intrusion, I was about to withdraw when Holmes pulled\n",
      " me abruptly into the room and closed the door behind me.\n",
      "\n",
      "“You could not possibly have come at a better time, my dear Watson,” he\n",
      "said cordially.\n",
      "\n",
      "“I was afraid that you were engaged.”\n",
      "\n",
      "“So I am. Very much so.”\n",
      "\n",
      "“Then I can wait in the next room.”\n",
      "\n",
      "“Not at all. This gentleman, Mr. Wilson, has been my partner and helper\n",
      "in many of my most successful cases, and I have no doubt that he will\n",
      "be of the utmost use to me in yours also.”\n",
      "\n",
      "The stout gentleman half rose from his chair and gave a bob of\n",
      "greeting, with a quick little questioning glance from his small\n",
      "fat-encircled eyes.\n",
      "\n",
      "Source: adventures_of_sherlock_holmes.txt\n",
      "\n",
      "Document 2:\n",
      "One night—it was on the twentieth of March, 1888—I was returning from a\n",
      "journey to a patient (for I had now returned to civil practice), when\n",
      "my way led me through Baker Street. As I passed the well-remembered\n",
      "door, which must always be associated in my mind with my wooing, and\n",
      "with the dark incidents of the Study in Scarlet, I was seized with a\n",
      "keen desire to see Holmes again, and to know how he was employing his\n",
      "extraordinary powers. His rooms were brilliantly lit, and, even as I\n",
      "looked up, I saw his tall, spare figure pass twice in a dark silhouette\n",
      "against the blind. He was pacing the room swiftly, eagerly, with his\n",
      "head sunk upon his chest and his hands clasped behind him. To me, who\n",
      "knew his every mood and habit, his attitude and manner told their own\n",
      "story. He was at work again. He had risen out of his drug-created\n",
      "dreams and was hot upon the scent of some new problem. I rang the bell\n",
      "and was shown up to the chamber which had formerly been in part my own.\n",
      "\n",
      "Source: adventures_of_sherlock_holmes.txt\n",
      "\n",
      "Document 3:\n",
      "I had seen little of Holmes lately. My marriage had drifted us away\n",
      "from each other. My own complete happiness, and the home-centred\n",
      "interests which rise up around the man who first finds himself master\n",
      "of his own establishment, were sufficient to absorb all my attention,\n",
      "while Holmes, who loathed every form of society with his whole Bohemian\n",
      "soul, remained in our lodgings in Baker Street, buried among his old\n",
      "books, and alternating from week to week between cocaine and ambition,\n",
      "the drowsiness of the drug, and the fierce energy of his own keen\n",
      "nature. He was still, as ever, deeply attracted by the study of crime,\n",
      "and occupied his immense faculties and extraordinary powers of\n",
      "observation in following out those clues, and clearing up those\n",
      "mysteries which had been abandoned as hopeless by the official police.\n",
      "From time to time I heard some vague account of his doings: of his\n",
      "summons to Odessa in the case of the Trepoff murder, of his clearing up\n",
      "of the singular tragedy of the Atkinson brothers at Trincomalee, and\n",
      "finally of the mission which he had accomplished so delicately and\n",
      "successfully for the reigning family of Holland. Beyond these signs of\n",
      "his activity, however, which I merely shared with all the readers of\n",
      "the daily press, I knew little of my former friend and companion.\n",
      "\n",
      "Source: adventures_of_sherlock_holmes.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs={\"device\": \"cpu\"}\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)\n",
    "query = \"How is Watson related to Sherlock Holmes?\"\n",
    "\n",
    "# Retrieve relevant documents based on the query\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.3},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# 3. Similarity Score Threshold\n",
    "# This method retrieves documents that exceed a certain similarity score threshold.\n",
    "# 'score_threshold' sets the minimum similarity score a document must have to be considered relevant.\n",
    "# Use this when you want to ensure that only highly relevant documents are retrieved, filtering out less relevant ones.\n",
    "\n",
    "# Display the relevant results with metadata\n",
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "    print(f\"Source: {doc.metadata['source']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='I had called upon my friend, Mr. Sherlock Holmes, one day in the\\n autumn of last year and found him in deep conversation with a very\\n stout, florid-faced, elderly gentleman with fiery red hair. With an\\n apology for my intrusion, I was about to withdraw when Holmes pulled\\n me abruptly into the room and closed the door behind me.\\n\\n“You could not possibly have come at a better time, my dear Watson,” he\\nsaid cordially.\\n\\n“I was afraid that you were engaged.”\\n\\n“So I am. Very much so.”\\n\\n“Then I can wait in the next room.”\\n\\n“Not at all. This gentleman, Mr. Wilson, has been my partner and helper\\nin many of my most successful cases, and I have no doubt that he will\\nbe of the utmost use to me in yours also.”\\n\\nThe stout gentleman half rose from his chair and gave a bob of\\ngreeting, with a quick little questioning glance from his small\\nfat-encircled eyes.'),\n",
       " Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='One night—it was on the twentieth of March, 1888—I was returning from a\\njourney to a patient (for I had now returned to civil practice), when\\nmy way led me through Baker Street. As I passed the well-remembered\\ndoor, which must always be associated in my mind with my wooing, and\\nwith the dark incidents of the Study in Scarlet, I was seized with a\\nkeen desire to see Holmes again, and to know how he was employing his\\nextraordinary powers. His rooms were brilliantly lit, and, even as I\\nlooked up, I saw his tall, spare figure pass twice in a dark silhouette\\nagainst the blind. He was pacing the room swiftly, eagerly, with his\\nhead sunk upon his chest and his hands clasped behind him. To me, who\\nknew his every mood and habit, his attitude and manner told their own\\nstory. He was at work again. He had risen out of his drug-created\\ndreams and was hot upon the scent of some new problem. I rang the bell\\nand was shown up to the chamber which had formerly been in part my own.'),\n",
       " Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='I had seen little of Holmes lately. My marriage had drifted us away\\nfrom each other. My own complete happiness, and the home-centred\\ninterests which rise up around the man who first finds himself master\\nof his own establishment, were sufficient to absorb all my attention,\\nwhile Holmes, who loathed every form of society with his whole Bohemian\\nsoul, remained in our lodgings in Baker Street, buried among his old\\nbooks, and alternating from week to week between cocaine and ambition,\\nthe drowsiness of the drug, and the fierce energy of his own keen\\nnature. He was still, as ever, deeply attracted by the study of crime,\\nand occupied his immense faculties and extraordinary powers of\\nobservation in following out those clues, and clearing up those\\nmysteries which had been abandoned as hopeless by the official police.\\nFrom time to time I heard some vague account of his doings: of his\\nsummons to Odessa in the case of the Trepoff murder, of his clearing up\\nof the singular tragedy of the Atkinson brothers at Trincomalee, and\\nfinally of the mission which he had accomplished so delicately and\\nsuccessfully for the reigning family of Holland. Beyond these signs of\\nhis activity, however, which I merely shared with all the readers of\\nthe daily press, I knew little of my former friend and companion.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\", #uses cosine similarity\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# 1. Similarity Search\n",
    "# This method retrieves documents based on vector similarity.\n",
    "# It finds the most similar documents to the query vector based on cosine similarity.\n",
    "# Use this when you want to retrieve the top k most similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='I had called upon my friend, Mr. Sherlock Holmes, one day in the\\n autumn of last year and found him in deep conversation with a very\\n stout, florid-faced, elderly gentleman with fiery red hair. With an\\n apology for my intrusion, I was about to withdraw when Holmes pulled\\n me abruptly into the room and closed the door behind me.\\n\\n“You could not possibly have come at a better time, my dear Watson,” he\\nsaid cordially.\\n\\n“I was afraid that you were engaged.”\\n\\n“So I am. Very much so.”\\n\\n“Then I can wait in the next room.”\\n\\n“Not at all. This gentleman, Mr. Wilson, has been my partner and helper\\nin many of my most successful cases, and I have no doubt that he will\\nbe of the utmost use to me in yours also.”\\n\\nThe stout gentleman half rose from his chair and gave a bob of\\ngreeting, with a quick little questioning glance from his small\\nfat-encircled eyes.'),\n",
       " Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='One night—it was on the twentieth of March, 1888—I was returning from a\\njourney to a patient (for I had now returned to civil practice), when\\nmy way led me through Baker Street. As I passed the well-remembered\\ndoor, which must always be associated in my mind with my wooing, and\\nwith the dark incidents of the Study in Scarlet, I was seized with a\\nkeen desire to see Holmes again, and to know how he was employing his\\nextraordinary powers. His rooms were brilliantly lit, and, even as I\\nlooked up, I saw his tall, spare figure pass twice in a dark silhouette\\nagainst the blind. He was pacing the room swiftly, eagerly, with his\\nhead sunk upon his chest and his hands clasped behind him. To me, who\\nknew his every mood and habit, his attitude and manner told their own\\nstory. He was at work again. He had risen out of his drug-created\\ndreams and was hot upon the scent of some new problem. I rang the bell\\nand was shown up to the chamber which had formerly been in part my own.'),\n",
       " Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='I had seen little of Holmes lately. My marriage had drifted us away\\nfrom each other. My own complete happiness, and the home-centred\\ninterests which rise up around the man who first finds himself master\\nof his own establishment, were sufficient to absorb all my attention,\\nwhile Holmes, who loathed every form of society with his whole Bohemian\\nsoul, remained in our lodgings in Baker Street, buried among his old\\nbooks, and alternating from week to week between cocaine and ambition,\\nthe drowsiness of the drug, and the fierce energy of his own keen\\nnature. He was still, as ever, deeply attracted by the study of crime,\\nand occupied his immense faculties and extraordinary powers of\\nobservation in following out those clues, and clearing up those\\nmysteries which had been abandoned as hopeless by the official police.\\nFrom time to time I heard some vague account of his doings: of his\\nsummons to Odessa in the case of the Trepoff murder, of his clearing up\\nof the singular tragedy of the Atkinson brothers at Trincomalee, and\\nfinally of the mission which he had accomplished so delicately and\\nsuccessfully for the reigning family of Holland. Beyond these signs of\\nhis activity, however, which I merely shared with all the readers of\\nthe daily press, I knew little of my former friend and companion.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Max Marginal Relevance (MMR)\n",
    "# This method balances between selecting documents that are relevant to the query and diverse among themselves.\n",
    "# 'fetch_k' specifies the number of documents to initially fetch based on similarity.\n",
    "# 'lambda_mult' controls the diversity of the results: 1 for minimum diversity, 0 for maximum.\n",
    "# Use this when you want to avoid redundancy and retrieve diverse yet relevant documents.\n",
    "# Note: Relevance measures how closely documents match the query.\n",
    "# Note: Diversity ensures that the retrieved documents are not too similar to each other,\n",
    "#       providing a broader range of information.\n",
    "\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\", #uses cosine similarity\n",
    "    search_kwargs={\"k\": 3, \"fetch_k\": 20, \"lambda_mult\": 0.5},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='I had called upon my friend, Mr. Sherlock Holmes, one day in the\\n autumn of last year and found him in deep conversation with a very\\n stout, florid-faced, elderly gentleman with fiery red hair. With an\\n apology for my intrusion, I was about to withdraw when Holmes pulled\\n me abruptly into the room and closed the door behind me.\\n\\n“You could not possibly have come at a better time, my dear Watson,” he\\nsaid cordially.\\n\\n“I was afraid that you were engaged.”\\n\\n“So I am. Very much so.”\\n\\n“Then I can wait in the next room.”\\n\\n“Not at all. This gentleman, Mr. Wilson, has been my partner and helper\\nin many of my most successful cases, and I have no doubt that he will\\nbe of the utmost use to me in yours also.”\\n\\nThe stout gentleman half rose from his chair and gave a bob of\\ngreeting, with a quick little questioning glance from his small\\nfat-encircled eyes.'),\n",
       " Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='“Fancy his having the insolence to confound me with the official\\ndetective force! This incident gives zest to our investigation,\\nhowever, and I only trust that our little friend will not suffer from\\nher imprudence in allowing this brute to trace her. And now, Watson, we\\nshall order breakfast, and afterwards I shall walk down to Doctors’\\nCommons, where I hope to get some data which may help us in this\\nmatter.”\\n\\nIt was nearly one o’clock when Sherlock Holmes returned from his\\nexcursion. He held in his hand a sheet of blue paper, scrawled over\\nwith notes and figures.'),\n",
       " Document(metadata={'source': 'adventures_of_sherlock_holmes.txt'}, page_content='“Oh, yes, mother is alive and well. I wasn’t best pleased, Mr. Holmes,\\nwhen she married again so soon after father’s death, and a man who was\\nnearly fifteen years younger than herself. Father was a plumber in the\\nTottenham Court Road, and he left a tidy business behind him, which\\nmother carried on with Mr. Hardy, the foreman; but when Mr. Windibank\\ncame he made her sell the business, for he was very superior, being a\\ntraveller in wines. They got £ 4700 for the goodwill and interest,\\nwhich wasn’t near as much as father could have got if he had been\\nalive.”\\n\\nI had expected to see Sherlock Holmes impatient under this rambling and\\ninconsequential narrative, but, on the contrary, he had listened with\\nthe greatest concentration of attention.\\n\\n“Your own little income,” he asked, “does it come out of the business?”')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relevant Documents ---\n",
      "Document 1:\n",
      "It was a cold morning of the early spring, and we sat after breakfast\n",
      "on either side of a cheery fire in the old room at Baker Street. A\n",
      "thick fog rolled down between the lines of dun-coloured houses, and the\n",
      "opposing windows loomed like dark, shapeless blurs through the heavy\n",
      "yellow wreaths. Our gas was lit and shone on the white cloth and\n",
      "glimmer of china and metal, for the table had not been cleared yet.\n",
      "Sherlock Holmes had been silent all the morning, dipping continuously\n",
      "into the advertisement columns of a succession of papers until at last,\n",
      "having apparently given up his search, he had emerged in no very sweet\n",
      "temper to lecture me upon my literary shortcomings.\n",
      "\n",
      "\n",
      "--- Generated Response ---\n",
      "Content only:\n",
      "The document mentions Sherlock Holmes as a main character in the scene. He was silent all morning, searching through advertisement columns in various papers. Eventually, he stopped searching and lectured the narrator about their literary shortcomings, indicating he was in a bad temper.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)\n",
    "\n",
    "# Define the user's question\n",
    "query = \"Summarize the information in the document mentioning Sherlock Holmes?\"\n",
    "\n",
    "# Retrieve relevant documents based on the query\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# Display the relevant results with metadata\n",
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "\n",
    "# Combine the query and the relevant document contents\n",
    "combined_input = (\n",
    "    \"Here are some documents that might help answer the question: \"\n",
    "    + query\n",
    "    + \"\\n\\nRelevant Documents:\\n\"\n",
    "    + \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    + \"\\n\\nPlease provide an answer based only on the provided documents. If the answer is not found in the documents, respond with 'I'm not sure'.\"\n",
    ")\n",
    "\n",
    "# Define the messages for the model\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=combined_input),\n",
    "]\n",
    "\n",
    "# Invoke the model with the combined input\n",
    "result = llm.invoke(messages)\n",
    "\n",
    "# Display the full result and content only\n",
    "print(\"\\n--- Generated Response ---\")\n",
    "# print(\"Full result:\")\n",
    "# print(result)\n",
    "print(\"Content only:\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the AI! Type 'exit' to end the conversation.\n",
      "AI: Your question seems to be missing. What would you like to ask about the provided context?\n",
      "AI: Sherlock Holmes is a brilliant and analytical detective who uses his extraordinary powers of observation and reasoning to solve crimes and unravel mysteries. He is the main character in a series of stories and has a unique ability to transform himself into different characters and personas to aid in his investigations.\n",
      "AI: Sherlock Holmes is a brilliant and analytical detective who uses his extraordinary powers of observation and reasoning to solve crimes and unravel mysteries. \n",
      "\n",
      "As for the story, the provided context appears to be the beginning of a collection of stories called \"The Adventures of Sherlock Holmes\" by Arthur Conan Doyle, but the specific story being referred to is not explicitly mentioned. However, it seems the narrator is about to share a remarkable case that was partially solved by Sherlock Holmes.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector store\n",
    "# `search_type` specifies the type of search (e.g., similarity)\n",
    "# `search_kwargs` contains additional arguments for the search (e.g., number of results to return)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "\n",
    "\n",
    "# Contextualize question prompt\n",
    "# This system prompt helps the AI understand that it should reformulate the question\n",
    "# based on the chat history to make it a standalone question\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, just \"\n",
    "    \"reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for contextualizing questions\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a history-aware retriever\n",
    "# This uses the LLM to help reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "# Answer question prompt\n",
    "# This system prompt helps the AI understand that it should provide concise answers\n",
    "# based on the retrieved context and indicates what to do if the answer is unknown\n",
    "qa_system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use \"\n",
    "    \"the following pieces of retrieved context to answer the \"\n",
    "    \"question. If you don't know the answer, just say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the answer \"\n",
    "    \"concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create a prompt template for answering questions\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a chain to combine documents for question answering\n",
    "# `create_stuff_documents_chain` feeds all retrieved context into the LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# Create a retrieval chain that combines the history-aware retriever and the question answering chain\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "# Function to simulate a continual chat\n",
    "def continual_chat():\n",
    "    print(\"Start chatting with the AI! Type 'exit' to end the conversation.\")\n",
    "    chat_history = []  # Collect chat history here (a sequence of messages)\n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "        # Process the user's query through the retrieval chain\n",
    "        result = rag_chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "        # Display the AI's response\n",
    "        print(f\"AI: {result['answer']}\")\n",
    "        # Update the chat history\n",
    "        chat_history.append(HumanMessage(content=query))\n",
    "        chat_history.append(SystemMessage(content=result[\"answer\"]))\n",
    "\n",
    "\n",
    "# Main function to start the continual chat\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma vectorstore created with: 2066 documents\n"
     ]
    }
   ],
   "source": [
    "print(f'Chroma vectorstore created with: {db._collection.count()} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vectors have 768 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "collection=db._collection\n",
    "sample_embedding=collection.get(limit=1,include=['embeddings'])['embeddings'][0]\n",
    "dimensions=len(sample_embedding)\n",
    "print(f'the vectors have {dimensions:,} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.get(limit=1,include=['embeddings'])['embeddings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
