{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatGroq(model='llama-3.1-70b-versatile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Prompt from Template------\n",
      "Why did the cat go to the vet?\n",
      "\n",
      "Because it was feeling a little cat-atrophic.\n",
      "\n",
      "Or here's another one:\n",
      "\n",
      "Why did the cat climb up the tree?\n",
      "\n",
      "To purr-suade the birds to come down.\n",
      "\n",
      "Or this one:\n",
      "\n",
      "What did the cat say when it was happy?\n",
      "\n",
      "\"I'm feline great!\"\n"
     ]
    }
   ],
   "source": [
    "print(\"-----Prompt from Template------\")\n",
    "template=\"Tell me a joke {topic}.\"\n",
    "prompt_template=ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt=prompt_template.invoke({\"topic\":\"cats\"})\n",
    "result=model.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Prompt with multiple placeholders ----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Prompt with Multiple Placeholders\n",
    "\n",
    "print(\"\\n ----- Prompt with multiple placeholders ----\\n\")\n",
    "template_multiple=\"\"\"You are a helpful assistant.\n",
    "Human: Tell me a {adjective} short story about a {animal}.\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "prompt_multiple=ChatPromptTemplate.from_template(template_multiple)\n",
    "prompt=prompt_multiple.invoke({\"adjective\":\"funny\",\"animal\":\"panda\"})\n",
    "\n",
    "result=model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One day, in a bamboo forest in China, there was a panda named Ping. Ping was a little clumsy and loved to dance. One sunny afternoon, while his panda friends were busy munching on bamboo shoots, Ping decided to practice his best ballet moves.\\n\\nAs he twirled and leaped through the forest, his big furry feet stomped on a beehive hidden in the underbrush. The bees, startled by the sudden noise, flew out and started chasing Ping.\\n\\nPanicked, Ping began to dance even faster, waving his paws wildly in the air. The bees, confused by the panda's crazy dance moves, started to get dizzy and disoriented.\\n\\nEventually, the bees got so tired from chasing Ping that they flew back to their hive, exhausted. Ping, still dancing, tripped and fell into a nearby mud pit.\\n\\nCovered in mud, Ping looked up at his friends, who were now laughing hysterically at the sight of the muddy panda. From that day on, Ping was known as the greatest (and most clumsy) panda dancer in the forest.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content=\"One day, in a bamboo forest in China, there was a panda named Ping. Ping was a little clumsy and loved to dance. One sunny afternoon, while his panda friends were busy munching on bamboo shoots, Ping decided to practice his best ballet moves.\\n\\nAs he twirled and leaped through the forest, his big furry feet stomped on a beehive hidden in the underbrush. The bees, startled by the sudden noise, flew out and started chasing Ping.\\n\\nPanicked, Ping began to dance even faster, waving his paws wildly in the air. The bees, confused by the panda's crazy dance moves, started to get dizzy and disoriented.\\n\\nEventually, the bees got so tired from chasing Ping that they flew back to their hive, exhausted. Ping, still dancing, tripped and fell into a nearby mud pit.\\n\\nCovered in mud, Ping looked up at his friends, who were now laughing hysterically at the sight of the muddy panda. From that day on, Ping was known as the greatest (and most clumsy) panda dancer in the forest.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 220, 'prompt_tokens': 55, 'total_tokens': 275, 'completion_time': 0.881222108, 'prompt_time': 0.013486264, 'queue_time': 0.005898483000000001, 'total_time': 0.894708372}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-d04c0235-b034-44e1-a496-12d9c6ea296b-0', usage_metadata={'input_tokens': 55, 'output_tokens': 220, 'total_tokens': 275})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Prompt with Sytem and Human messages (Tuple) -----\n",
      "messages=[SystemMessage(content='You are a comedian who tells jokes about lawyers.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me 4 jokes.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Part 3: Prompt with System and Human messages (using Tuples)\n",
    "messages = [\n",
    "    ('system', 'You are a comedian who tells jokes about {topic}.'),\n",
    "    ('human', 'Tell me {joke_count} jokes.')\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({'topic': 'lawyers', 'joke_count': 4})\n",
    "print(f\"----- Prompt with Sytem and Human messages (Tuple) -----\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt with System and Human Messages:\n",
      "messages=[SystemMessage(content='You are a comedian who tells jokes about lawyers.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me 3 jokes', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# This work\n",
    "messages = [\n",
    "    ('system', 'You are a comedian who tells jokes about {topic}.'),\n",
    "    HumanMessage(content=\"Tell me 3 jokes\")\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({'topic': 'lawyers'})\n",
    "\n",
    "# # This does not work\n",
    "# messages = [\n",
    "#     ('system', 'You are a comedian who tells jokes about {topic}.'),\n",
    "#     HumanMessage(content=\"Tell me {joke_count} jokes\")\n",
    "# ]\n",
    "# prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "# prompt = prompt_template.invoke({'topic': 'lawyers', 'joke_count': 4})\n",
    "\n",
    "print(f\"Prompt with System and Human Messages:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three lawyer jokes for you:\n",
      "\n",
      "1. Why did the lawyer's client bring a ladder to the courtroom? Because he wanted to take his case to a higher court. \n",
      "\n",
      "2. Why did the lawyer's dog go to the vet? Because it was feeling a little ruff, but the lawyer just wanted to get a paws-itive verdict.\n",
      "\n",
      "3. Why did the lawyer cross the road? To get to the other side... of the argument, where the billable hours were better.\n"
     ]
    }
   ],
   "source": [
    "# Langchain Expression Language (LCEL)  => chain= prompt | model\n",
    "# result=chain.invoke({\"key\":\"value\"})  this key is passed to prompt which then passes its output to model.\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are a comedian who tells jokes about {topic}'),\n",
    "        ('human'), 'Tell me {joke_count} jokes.'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combined chain using Langchain Expression Language (LCEL)\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "result = chain.invoke({'topic': 'lawyers', 'joke_count': 3})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains - Under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A human, that's a great warm-up. Alright, here are three lawyer jokes for you:\n",
      "\n",
      "1. Why did the lawyer's dog go to the vet?\n",
      "Because it was feeling ruff justice.\n",
      "\n",
      "2. Why did the lawyer's client bring a ladder to the courtroom?\n",
      "Because he wanted to take his case to a higher court.\n",
      "\n",
      "3. Why did the lawyer cross the road?\n",
      "To get to the other side... of the argument. (ba-dum-tss)\n"
     ]
    }
   ],
   "source": [
    "# Create individual runnables (steps in the chain)\n",
    "format_prompt = RunnableLambda(lambda x: prompt_template.format_prompt(**x)) # Replace the input_variables with the actual values \n",
    "invoke_model = RunnableLambda(lambda x: model.invoke(x.to_messages()))\n",
    "parse_output = RunnableLambda(lambda x: x.content)\n",
    "\n",
    "# Create the RunnableSequence (Equivalent to the LCEL chain)\n",
    "chain = RunnableSequence(first=format_prompt, middle=[invoke_model],last=parse_output)\n",
    "response=chain.invoke({'topic': 'lawyers', 'joke_count': 3})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count: 98\n",
      "HERE ARE THREE JOKES ABOUT LAWYERS:\n",
      "\n",
      "1. WHY DID THE LAWYER'S CLIENT BRING A LADDER TO THE COURTROOM? BECAUSE HE WANTED TO TAKE HIS CASE TO A HIGHER COURT.\n",
      "\n",
      "2. WHY DID THE LAWYER'S DOG GO TO THE VET? IT WAS FEELING A LITTLE RUFF, AND THE LAWYER SAID, 'DON'T WORRY, I'LL PAWS FOR A MOMENT AND SUE THE VET IF THEY DON'T GIVE YOU THE BEST CARE.'\n",
      "\n",
      "3. WHY DID THE LAWYER CROSS THE ROAD? TO GET TO THE OTHER SIDE... OF THE ARGUMENT, WHERE HE COULD BILL HIS CLIENT FOR THE EXTRA HOUR OF WALKING TIME.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are a comedian who tells jokes about {topic}'),\n",
    "        ('human'), 'Tell me {joke_count} jokes.'\n",
    "    ]\n",
    ")\n",
    "\n",
    "uppercase_output=RunnableLambda(lambda x: x.upper())\n",
    "count_words=RunnableLambda(lambda x: f\"word count: {len(x.split())}\\n{x}\")\n",
    "\n",
    "chain=prompt_template | model | StrOutputParser() | uppercase_output | count_words\n",
    "\n",
    "result=chain.invoke({'topic': 'lawyers', 'joke_count': 3})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert product reviewer.\"),\n",
    "        (\"human\",\"List the main features of the product {product_name}.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pros(features):\n",
    "    pros_template=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\",\"You are an expert product reviewer.\"),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Given these features: {features}, list the pros of these features.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return pros_template.format_prompt(features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cons(features):\n",
    "    cons_template=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\",\"You are an expert product reviewer.\"),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Given these features: {features}, list the cons of these features.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return cons_template.format_prompt(features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pros_cons(pros, cons):\n",
    "    return f\"Pros:\\n{pros}\\n\\nCons:\\n{cons}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pros_branch=(\n",
    "    RunnableLambda(lambda x: analyze_pros(x)) | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "cons_branch=(\n",
    "    RunnableLambda(lambda x: analyze_cons(x)) | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=(\n",
    "    prompt_template\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | RunnableParallel(branches={\"pros\":pros_branch, \"cons\": cons_branch})\n",
    "    | RunnableLambda(lambda x: combine_pros_cons(x[\"branches\"][\"pros\"], x[\"branches\"][\"cons\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pros:\n",
      "Based on the features of the Google Pixel 6a, here are the pros:\n",
      "\n",
      "1. **Vibrant Display**: The 6.1-inch OLED display provides vibrant colors and a smooth viewing experience, making it perfect for watching videos and browsing the web.\n",
      "2. **Fast Performance**: The Google Tensor processor offers fast performance, allowing users to multitask and switch between apps seamlessly.\n",
      "3. **Impressive Camera Capabilities**: The dual-camera setup with a 12.2MP primary sensor and a 12.2MP ultra-wide-angle lens provides excellent camera performance, and the 8MP front camera is great for selfies.\n",
      "4. **All-Day Battery Life**: The 4410mAh battery provides all-day battery life, and fast charging up to 18W ensures that users can quickly top up their battery when needed.\n",
      "5. **Timely Software Updates**: The Pixel 6a receives timely software updates directly from Google, ensuring that users have the latest security patches and features.\n",
      "6. **Secure Biometric Authentication**: The rear-mounted fingerprint sensor provides secure biometric authentication, giving users peace of mind when it comes to protecting their device.\n",
      "7. **Dust and Water-Resistant**: The IP67 rating means that the device is protected against accidental splashes and spills, providing users with added peace of mind.\n",
      "8. **Affordable Price**: The Pixel 6a is priced affordably, making it an attractive option for those looking for a budget-friendly smartphone with impressive features.\n",
      "9. **Expandable Storage**: The device comes with a microSD card slot, allowing users to expand their storage capacity if needed.\n",
      "10. **Color Options**: The Pixel 6a is available in three colors (Sage, Chalk, and Charcoal), giving users a range of options to choose from.\n",
      "\n",
      "Overall, the Google Pixel 6a offers a great balance of performance, camera capabilities, and affordability, making it a compelling choice for those in the market for a mid-range Android smartphone.\n",
      "\n",
      "Cons:\n",
      "While the Google Pixel 6a has many impressive features, some potential drawbacks include:\n",
      "\n",
      "1. **Display**: \n",
      "   - The 6.1-inch OLED display may be too small for some users who prefer larger screens.\n",
      "   - There is no high refresh rate (e.g., 90Hz or 120Hz) available on this device, which may result in a slightly less smooth experience.\n",
      "\n",
      "2. **Processors**: \n",
      "   - Although the Tensor processor provides fast performance, it may not be as powerful as some flagship processors.\n",
      "\n",
      "3. **Camera**: \n",
      "   - The 12.2MP primary sensor and ultra-wide-angle lens, while good, may not be able to compete with higher-end camera setups.\n",
      "   - There is no telephoto lens or periscope lens, which may limit the camera's zoom capabilities.\n",
      "\n",
      "4. **Battery**: \n",
      "   - Although the 4410mAh battery provides all-day battery life, it may not be sufficient for heavy users.\n",
      "   - The fast charging speed is capped at 18W, which is relatively slow compared to other devices.\n",
      "\n",
      "5. **Software**: \n",
      "   - Although the device runs on Android 11 out of the box, it may not be the latest version available.\n",
      "   - Some users may experience compatibility issues with certain apps due to the device's mid-range hardware.\n",
      "\n",
      "6. **Storage and RAM**: \n",
      "   - The 6GB of RAM may not be sufficient for heavy users who multitask frequently.\n",
      "   - The 128GB internal storage may not be enough for users who have large collections of photos, videos, or apps.\n",
      "\n",
      "7. **Fingerprint sensor**: \n",
      "   - The rear-mounted fingerprint sensor may be inconvenient for some users who prefer in-display fingerprint scanners.\n",
      "\n",
      "8. **IP67 rating**: \n",
      "   - Although the device is dust and water-resistant, it is not completely waterproof and may still be damaged by prolonged exposure to water.\n",
      "\n",
      "9. **Colors**: \n",
      "   - The limited color options (Sage, Chalk, and Charcoal) may not appeal to users who prefer more vibrant or bold colors.\n",
      "\n",
      "10. **Price**: \n",
      "    - Although the device is priced affordably, some users may be able to find similar devices with comparable features at a lower price point.\n",
      "\n",
      "Overall, while the Google Pixel 6a offers many impressive features, some users may find the device's limitations to be significant drawbacks.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"product_name\": \"Pixel 6a\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Google Pixel 6a is a mid-range Android smartphone released in 2022. Here are its main features:\n",
      "\n",
      "1. **Display**: 6.1-inch OLED display with a resolution of 1080 x 2400 pixels, 60Hz refresh rate, and HDR support.\n",
      "\n",
      "2. **Processor**: Google Tensor chip, a 2.8 GHz octa-core processor paired with 6GB of RAM and 128GB of internal storage.\n",
      "\n",
      "3. **Camera**: Dual-camera setup with a 12.2 MP primary sensor, 8 MP front camera, and support for 4K video recording at 30fps.\n",
      "\n",
      "4. **Battery**: 4410mAh battery with 18W fast charging support and wireless charging capabilities.\n",
      "\n",
      "5. **Software**: The device runs on Android 12 out of the box, with a promise of up to 5 years of security updates.\n",
      "\n",
      "6. **Biometric security**: In-display fingerprint sensor for secure biometric authentication.\n",
      "\n",
      "7. **Connectivity**: 5G connectivity, Wi-Fi 6, Bluetooth 5.2, NFC, and a USB-C port.\n",
      "\n",
      "8. **Durability**: IP67 rating for dust and water resistance, with a durable design featuring a Gorilla Glass 3 front panel and a polycarbonate back.\n",
      "\n",
      "9. **Colors**: The Pixel 6a is available in three colors: Charcoal, Sage, and Chalk.\n",
      "\n",
      "10. **Additional features**: The device supports Google Assistant, Google Lens, Night Sight mode, Portrait mode, and more exclusive features.\n"
     ]
    }
   ],
   "source": [
    "chain=(prompt_template\n",
    "    | model\n",
    "    | StrOutputParser())\n",
    "    \n",
    "print(chain.invoke({\"product_name\": \"Pixel 6a\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branching Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_feedback_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "        \"Generate a thank you note for this positive feedback: {feedback}.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_feedback_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "        \"Generate a response addressing this negative feedback: {feedback}.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_feedback_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "        \"Generate a request for more details for this neutral feedback: {feedback}.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalate_feedback_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "        \"Generate a message to escalate this feedback to a human agent: {feedback}.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "        \"Classify the sentiment of this feedback as positive, negative, neutral or escalate: {feedback}.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches=RunnableBranch(\n",
    "    (\n",
    "        lambda x:\"positive\" in x,\n",
    "        positive_feedback_template | model |StrOutputParser()\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"negative\" in x,\n",
    "        negative_feedback_template | model | StrOutputParser()\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"neutral\" in x,\n",
    "        neutral_feedback_template | model | StrOutputParser()\n",
    "    ),\n",
    "    escalate_feedback_template | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_chain=classification_template | model | StrOutputParser()\n",
    "\n",
    "chain= classification_chain | branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear [Customer],\n",
      "\n",
      "Thank you for taking the time to share your feedback about our product. We apologize that it did not meet your expectations. We are truly sorry to hear that the product broke after just one use, and we understand how frustrating that must be.\n",
      "\n",
      "We take all issues with our products seriously and would like to make things right. We would like to offer you a replacement or a full refund, whichever you prefer. Please let us know which option you would like to choose, and we will expedite the process as quickly as possible.\n",
      "\n",
      "Regarding the color, we appreciate your feedback and will take it into consideration for future product development. We understand that color preferences are subjective, and we will do our best to provide a wider range of options in the future.\n",
      "\n",
      "If you have any further concerns or issues, please do not hesitate to contact us. We value your feedback and would like the opportunity to make things right. Your satisfaction is our top priority, and we appreciate the chance to serve you better.\n",
      "\n",
      "Thank you for your feedback, and we look forward to the opportunity to serve you better in the future.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "review=\" The product is terrible. It broke after just one use and I hate the colour.\"\n",
    "result=chain.invoke({\"feedback\": review})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a possible thank-you note in response to the positive feedback:\n",
      "\n",
      "Dear [Name],\n",
      "\n",
      "I just wanted to take a moment to express my heartfelt thanks for your wonderful feedback! I'm beyond thrilled to hear that you loved everything about [product/service/experience] and found it to be \"awesome\" and \"so cool.\" Your kind words mean the world to me, and I'm grateful for your enthusiasm and support.\n",
      "\n",
      "Thank you again for taking the time to share your thoughts and for being an amazing [customer/user/etc.]. I'm honored to have had the opportunity to serve you and look forward to continuing to provide you with exceptional experiences in the future.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "review=\" The product is Awesome!!!. I loved everything about it and it's so cool.\"\n",
    "result=chain.invoke({\"feedback\": review})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a possible thank-you note for neutral feedback:\n",
      "\n",
      "Dear [Customer],\n",
      "\n",
      "Thank you for taking the time to share your thoughts about our product. We appreciate your feedback and are glad to hear that it's serving its purpose for you. We're always working to improve and appreciate your input in helping us achieve that goal.\n",
      "\n",
      "Thank you again for your purchase and for being a valued customer.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "\n",
      "This response acknowledges the customer's feedback without taking it as overly positive or negative. It shows appreciation for their input and expresses a commitment to continuous improvement.\n"
     ]
    }
   ],
   "source": [
    "review=\" The product an alright product. Does the job so there's that.\"\n",
    "result=chain.invoke({\"feedback\": review})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
